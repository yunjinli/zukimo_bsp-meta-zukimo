<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Radar SDK Documentation: Python wrapper usage</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ifx_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Radar SDK Documentation
   &#160;<span id="projectnumber">v3.3.1</span>
   </div>
   <div id="projectbrief">Infineon Radar SDK for evaluation and development of applications with Infineon XENSIV 60GHz radar sensors.</div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('pg_rdk_python.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Python wrapper usage </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="sct_rdk_python_quick"></a>
Avian Python Wrapper</h1>
<h2><a class="anchor" id="sct_rdk_python_installation"></a>
Installation</h2>
<p>The Avian Python wrapper requires Python 3 and numpy. The wrapper has been tested with Python versions 3.7, 3.8, 3.9 and 3.10.</p>
<p>If Python is not yet installed on your computer, it is recommended to install the <a href="https://www.anaconda.com/products/distribution">Anaconda distribution</a> (available for Windows and Linux) which includes Python, numpy, scipy and many more packages. On Windows make sure that you install a 64bit version of Python.</p>
<p>On Linux you can also use the package manager of your distribution to install python the required packages. For example on Raspbian and Ubuntu, you need to install the packages <code>python3</code> and <code>python3-numpy</code>. In addition, the packages <code>python3-scipy</code> and <code>python3-matplotlib</code> are required by some example applications: </p><pre class="fragment">sudo apt install python3 python3-numpy python3-scipy python3-matplotlib
</pre><p>Python wheels for the Avian Python wrapper are available for Windows 10 (64bit), Linux (Ubuntu 20.04, 64bit) and Raspberry Pi (Raspbian Buster, 32bit). In the release package of the Radar SDK the wheels are available in the subfolders for the respective platforms in the directory <code>libs/</code>. The Python wheel can be installed using Python's package installer pip, for example: </p><pre class="fragment">pip install ifxAvian-X.Y.Z-py3-none-any.whl
</pre><p>On platforms which are not officially supported you can create the Python wheel using cmake. First, make sure that Python is in the PATH and that the Python package <code>wheel</code> is installed. Then, follow the instructions on the page <a class="el" href="pg_radarsdk_setup_build_environment.html">Building SDK from source code</a> and build the target <code>wheel_avian</code>. The Python wheel will then be available in your build directory in the folder <code>wheel_avian/dist</code>.</p>
<p>If you create the Python wheel on Windows with MinGW, please make sure that the libraries <code>libwinpthread-1.dll</code>, <code>libstdc++-6.dll</code> and <code>libgcc_s_seh-1.dll</code> are in the search PATH and can be found by the Python module.</p>
<h2><a class="anchor" id="sct_rdk_python_running_the_example"></a>
Running the examples</h2>
<p>A simple example script can be found in the directory <code>sdk/py/wrapper_avian</code> of the release package. The script <code>example.py</code> connects to the first radar sensor found, sets a default configuration and fetches 10 frames. If successful, the output should look similar as shown in Figure 1.1.</p>
<p>If the script aborts with the error <code>ModuleNotFoundError</code> make sure that you have followed the steps in section <a class="el" href="pg_rdk_python.html#sct_rdk_python_installation">Installation</a>. If the script fails with the exception <code>ErrorNoDevice</code> no radar sensor could be found. Make sure that a radar sensor is connected to the computer and that the status LED on the board is flashing green. Also make sure that you are using the latest firmware for the connected board. On Linux make sure that you have access to the device file <code>/dev/ttyACM0</code>, for more information please refer to <a class="el" href="pg_radarsdk_setup_build_environment.html#ssct_radarsdk_setup_build_environmenton_linux">Linux</a>.</p>
<div class="image">
<img src="img_python_fig_1_output_of_example.png" alt="" width="600px"/>
<div class="caption">
Figure 1.1 Output of example.py.</div></div>
<p> <br  />
 The script <code>example_cw.py</code> is similar to <code>example.py</code> and illustrates how to configure the sensor in constant wave (CW) mode.</p>
<p>The script <code>example_recording.py</code> is similar to <code>example.py</code> and illustrates how to start and use a device handle from a saved recording.</p>
<h2><a class="anchor" id="sct_rdk_python_help_function"></a>
Help and Documentation</h2>
<p>To get further information about the functions and methods of the Avian Python wrapper, please use Python's help function to see the full documentation:</p>
<pre class="fragment">Python 3.8.5 (default, Jul 28 2020, 12:59:40)
[GCC 9.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from ifxAvian import Avian
&gt;&gt;&gt; help(Avian)
</pre><p>The output looks similar as depicted in Figure 1.2. Integrated development environments typically also allow to read this documentation.</p>
<div class="image">
<img src="img_python_fig_2_documentation_of_the_python.png" alt="" width="600px"/>
<div class="caption">
Figure 1.2 Documentation of the Python SDK wrapper as shown by the function help.</div></div>
<h2><a class="anchor" id="sct_rdk_python_running_applications"></a>
Running the example applications</h2>
<p>The Python example application can be found in the folder <code>apps/py/examples/</code>. When starting the applications, additional parameters can be passed to configure the number of frames or the frame rate. Passing the flag <code>-h</code> will show the possible options for each example application.</p>
<p>Starting the script <code>static_distance.py</code> allows to measure distance to static targets like walls. The output should be similar to Figure 1.3.</p>
<div class="image">
<img src="img_python_fig_4_output_of_running_static_distance.png" alt="" width="600px"/>
<div class="caption">
Figure 1.3 Output of running static_distance.py.</div></div>
<p>The script <code>doppler.py</code> computes and plots the Range-Doppler map for each receiving antenna. Figure 1.4 shows a Range-Doppler map as outputted by the script.</p>
<div class="image">
<img src="img_python_fig_5_range_doppler_map_ass_displayed_by_doppler.png" alt="" width="600px"/>
<div class="caption">
Figure 1.4 The Range-Doppler map as displayed by doppler.py.</div></div>
<p> The magnitude in dB is shown as a function of velocity and distance.</p>
<h1><a class="anchor" id="sct_rdk_python_algo"></a>
Writing a Radar application using Python</h1>
<p>This section illustrates the usage of the Avian Python wrapper. The examples can be used as a starting point for writing custom applications. Typically, a program will import the Python wrapper, connect to the Avian radar sensor, set a specific Radar configuration and then in a loop fetch time-domain data from the sensor and process it.</p>
<h2><a class="anchor" id="sct_rdk_python_algo_import"></a>
Importing the Python wrapper</h2>
<p>The first step is to import the Python wrapper. Additionally, the numpy library is imported here as it is used for calculations (e.g Fast Fourier Transform, shape, pad etc.) in this example.</p>
<pre class="fragment">from ifxAvian import Avian
import numpy as np
</pre><p>Once the library is imported, the version can be checked using <code>get_version</code>:</p>
<pre class="fragment">Avian.get_version()          # get brief version
Avian.get_version(full=True) # get full version
</pre><h2><a class="anchor" id="sct_rdk_python_algo_connect"></a>
Connecting to the Radar sensor</h2>
<p>Next, a connection to a Radar sensor is established. Make sure that the Radar board is connected to your computer. To connect to the first Radar board found, you can either use</p>
<pre class="fragment">device = Avian.Device()
</pre><p>or </p><pre class="fragment">with Avian.Device() as device:
     #block code
     #block code
     ...
     #block code
</pre><p>The later version using the <code>with</code> statement has the advantage that the connection to the Radar board is automatically closed after leaving the <code>with</code> block. In the code that doesn't use the <code>with</code> statement, you have to manually disconnect using</p>
<pre class="fragment">del device
</pre><p>It is also possible to connect to a Radar sensor with a specific UUID:</p>
<pre class="fragment">device = Avian.Device(uuid="01234567-89ab-cdef-0123-456789abcdef")
</pre><p>To get a list of all connected Radar sensors you can use the method </p><pre class="fragment">Avian.Device.get_list()
</pre><p>For more details, please refer to the documentation of the Python wrapper (<a class="el" href="pg_rdk_python.html#sct_rdk_python_help_function">Help and Documentation</a>).</p>
<h2><a class="anchor" id="sct_rdk_python_algo_config"></a>
Setting a Radar configuration</h2>
<p>A particular configuration is written to the Radar sensor in the next step. The following snippet shows how to get a default configuration and how to set this configuration:</p>
<pre class="fragment">config = device.get_config_defaults()
device.set_config(config)
</pre><p>Here is an example for setting a full configuration:</p>
<pre class="fragment">config = Avian.DeviceConfig(
    sample_rate_Hz = 1_000_000,       # ADC sample rate of 1MHZ
    rx_mask = 5,                      # activate RX1 and RX3
    tx_mask = 1,                      # activate TX1
    if_gain_dB = 33,                  # gain of 33dB
    tx_power_level = 31,              # TX power level of 31
    start_frequency_Hz = 60e9,        # start frequency of chirp: 60GHz
    end_frequency_Hz = 61.5e9,        # end frequency of chirp: 61.5GHz
    num_chirps_per_frame = 128,       # 128 chirps per frame
    num_samples_per_chirp = 64,       # 64 samples per chirp
    chirp_repetition_time_s = 0.0005, # 0.5ms
    frame_repetition_time_s = 0.2,    # 0.2s, frame_Rate = 5Hz
    hp_cutoff_Hz = 80_000,            # 80kHz cutoff frequency for high-pass filter
    aaf_cutoff_Hz = 500_000,          # Anti-aliasinf cutoff frequency of 500kHz
    mimo_mode = 'off'                 # MIMO disabled
)
device.set_config(config)
</pre><p>Please note that this configuration will not work on all radar sensors. For example, the BGT60UTR11AIP only has 1 RX antenna. For a BGT60UTR11AIP the method <code>set_config</code> will consequently raise an exception.</p>
<p>You can read back the current configuration using the method <code>get_config</code>. Due to rounding of timings the configuration given to <code>set_config</code> and the configuration that was actually applied will always differ a bit. For example, reading back the configuration applied yields:</p>
<pre class="fragment">&gt;&gt;&gt; print(device.get_config())
DeviceConfig:
    sample_rate_Hz: 1000000
    rx_mask: 5
    tx_mask: 1
    tx_power_level: 31
    if_gain_dB: 33
    start_frequency_Hz: 60000000000
    end_frequency_Hz: 61500000000
    num_samples_per_chirp: 64
    num_chirps_per_frame: 128
    chirp_repetition_time_s: 0.0005000000237487257
    frame_repetition_time_s: 0.20000000298023224
    hp_cutoff_Hz: 80000
    mimo_mode: off
</pre><p>For more information on the configuration refer to the Python documentation of <code>DeviceConfig</code> </p><pre class="fragment">help(Avian.DeviceConfig)
</pre><p> and to the documentation of <a class="el" href="structifx___avian___config__t.html">ifx_Avian_Config_t</a>.</p>
<h2><a class="anchor" id="sct_rdk_python_algo_data"></a>
Fetching Radar data</h2>
<p>Once the device configuration is set, the Radar is now ready to start receiving samples from the configured antennas. The following code snippet can be used as an example to get a frame of data. This code can be structured as a loop block for <code>num_frames</code> number of frames as shown below:</p>
<pre class="fragment"># A loop for fetching a finite number of frames
for frame_number in range(num_frames):
    frame = device.get_next_frame()
</pre><p>The device starts to send data samples from each configured antenna at the frame repetition rate. The frame is returned as a numpy array with shape <code>num_rx_antennas</code> x <code>num_chirps_per_frame</code> x <code>num_samples_per_shape</code>:</p>
<pre class="fragment"># shape of the frame
num_rx_antennas, num_chirps_per_frame, num_samples_per_chirp = np.shape(frame)
</pre><p><code>num_chirps_per_frame</code> and <code>num_samples_per_chirp</code> correspond to the respective options of the same names of the configuration. The value of <code>num_rx_antennas</code> corresponds to the number of bits set in <code>rx_mask</code> of the configuration if MIMO mode is disabled. If MIMO mode is enabled, <code>num_rx_antennas</code> corresponds to two times the number of bits set in <code>rx_mask</code>.</p>
<h2><a class="anchor" id="sct_rdk_python_running_the_algoexample"></a>
A presence sensing application</h2>
<p>This section illustrates how to write a simple application for presence detection. The code snippets illustrate the main steps, the actual implementation is in the file presence_detection.py in the directory apps/py/examples/.</p>
<h3><a class="anchor" id="sct_rdk_python_presence_config"></a>
Configuring the Radar and algorithm</h3>
<p>The Radar is tuned so the presence sensing returns "true" when it detects an object in the range of 20-80cm from the Radar shield's planar face. The configuration can be derived using these requirements. For details on how to derive the configuration please refer to <a class="el" href="pg_radarsdk_device_config_guide.html#ssct_radarsdk_device_config_guide_params">Radar device configuration parameters</a>. The following configuration is used to configure a single receive antenna and a detection range of 1.6 meters.</p>
<pre class="fragment"># set device configuration for presence sensing
config = Avian.DeviceConfig(
    sample_rate_Hz = 1e6,                  # ADC sample rate of 1MHz
    rx_mask = 1,                           # RX antenna 1 activated
    tx_mask = 1,                           # TX antenna 1 activated
    tx_power_level = 31,                   # TX power level of 31
    if_gain_dB = 33,                       # 33dB if gain
    start_frequency_Hz = 59_133_931_281,   # start frequency: 59.133931281 GHz
    end_frequency_Hz = 62_366_068_720,     # end frequency: 62.366068720 GHz
    num_samples_per_chirp = 64,            # 64 samples per chirp
    num_chirps_per_frame = 32,             # 32 chirps per frame
    chirp_repetition_time_s = 0.000411238, # Chirp repetition time (or pulse repetition time) of 411.238us
    frame_repetition_time_s = 0.125,       # Frame repetition time of 0.125s (frame rate of 8Hz)
    hp_cutoff_Hz = 80_000                  # 80kHz cutoff frequency for high-pass filter
    mimo_mode = "off")                     # MIMO disabled
device.set_config(config)
</pre><p>The algorithm needs certain parameters which are used in subsequent steps and are configured/initialized as</p>
<pre class="fragment"># Presence sensing algorithm parameters
detect_start_sample = chirpsamples//8 # detection start sample corresponding to 20cm
detect_end_sample = chirpsamples//2   # detection end sample corresponding to 80cm
threshold_presence = 0.0007           # threshold for object detection
alpha_slow = 0.001                    # slow average update coefficient
alpha_med = 0.05                      # medium average update coefficient
alpha_fast = 0.6                      # fast average update coefficient
</pre><p>This configures a detection range of 20cm to 80cm. The threshold presence is set to a value based on experimentation giving a reasonable detection with an object presence e.g. a hand.</p>
<h3><a class="anchor" id="sct_rdk_python_fft_spectrum"></a>
Computing Radar distance data</h3>
<p>Once the antenna '0' data is available in the variable 'mat', the range FFT is computed using the following steps:</p>
<dl class="section user"><dt>Step 1: remove DC bias from samples</dt><dd><pre class="fragment">mat = frame[0, :, :]
avgs = np.average(mat,1).reshape(numchirps,1)
mat = mat - avgs
</pre></dd></dl>
<dl class="section user"><dt>Step 2: Window the data before zero padding</dt><dd></dd></dl>
<p>To compute the Blackman-Harris window we use the <code>scipy.signal</code> package. Import <code>scipy.signal</code> at the beginning of the script </p><pre class="fragment">import scipy.signal as signal
</pre><p> and use the function <code>blackmanharris</code> to compute the window: </p><pre class="fragment">import scipy.signal as signal
[...]
mat = np.multiply(mat,signal.blackmanharris(chirpsamples).reshape(1,chirpsamples))
</pre><dl class="section user"><dt>Step 3: Add zero padding for higher resolution FFT</dt><dd><pre class="fragment">zp1 = np.pad(mat,((0,0),(0,chirpsamples)),'constant')
</pre></dd></dl>
<dl class="section user"><dt>Step 4: compute FFT and select the non zero spectrum for Range information</dt><dd><pre class="fragment">range_fft = np.fft.fft(zp1)/chirpsamples
range_fft = 2*range_fft[:,range(int(chirpsamples))]
</pre></dd></dl>
<p>The above steps used to compute distance data have been compiled in a Python function 'fft_spectrum.py' residing in the SDK Python wrapper directory.</p>
<h3><a class="anchor" id="sct_rdk_python_presence_algo"></a>
Presence sensing algorithm</h3>
<p>To detect presence, the absolute values of the range FFT data are averaged over chirps in a frame and filtered with a slow single tap IIR filter and a fast single tap IIR filter.</p>
<dl class="section user"><dt>Step 1: Compute absolute FFT values and chirp average</dt><dd></dd></dl>
<p>In this step, the absolute FFT values are computed and averaged over the chirps in the frame.</p>
<dl class="section user"><dt></dt><dd><pre class="fragment">fft_abs = abs(range_fft)
fft_avg = np.divide(fft_abs.sum(axis=0), numchirps)
</pre></dd></dl>
<dl class="section user"><dt>Step 2: Compute slow and fast average updates</dt><dd></dd></dl>
<p>The slow and fast average vectors are initialized to the first 'fft_avg'. The slow averaging coefficient is chosen depending on the detection status. The idea is to slow down the reference update once an object is detected. </p><dl class="section user"><dt></dt><dd><pre class="fragment">if frame_number == 0: # initialize average updates
    slow_avg = fft_avg
    fast_avg = fft_avg

# Choose slow coefficient
if presence_status == False:
    alpha_used = alpha_med
else:
    alpha_used = alpha_slow

slow_avg = slow_avg*(1-alpha_used) + fft_avg*alpha_used
fast_avg = fast_avg*(1-alpha_fast) + fft_avg*alpha_fast
data = (fast_avg-slow_avg)
</pre></dd></dl>
<p>For detection, the difference between the fast filtered output and the slow filtered output ('data') can be used to identify the appearance of a new object in the detection range. The presence state decision is then made based on a threshold. The detection range and speed of slow and fast filtering can be treated as algorithm parameters.</p>
<dl class="section user"><dt>Step 3: Detection Logic</dt><dd><pre class="fragment">presence_status = (np.max(data[detect_start_sample:detect_end_sample])&gt;threshold_presence)
</pre></dd></dl>
<h2><a class="anchor" id="sct_rdk_python_algoext"></a>
Extension into an anti-peeking application</h2>
<p>as mentioned in <a class="el" href="pg_rdk_python.html#sct_rdk_python_running_the_algoexample">A presence sensing application</a>, the detection range and the speed of slow and fast filtering can be treated as algorithm parameters. For a slightly more complex anti-peeking application showcasing the Radar's multiple object detection capability, a second instance of of the algorithm needs to be run on the same data with a different set of range and threshold parameters.</p>
<dl class="section user"><dt>Use Case</dt><dd></dd></dl>
<p>The intention of this application is a scenario where the radar is mounted on your laptop screen and the intention is to detect the user and an additional alarm when someone peeking from behind is detected. For this purpose it is required to define an additional start and end range.</p>
<div class="image">
<img src="img_python_fig_2_output_of_presence_det.png" alt="" width="600px"/>
<div class="caption">
Figure 2.1 Output of presence_detection.py.</div></div>
<p>The same algorithm is run twice resulting in two detections as can be seen from the example app output in Figure 2.1. This application can be found in the folder <code>apps/py/examples/presence_detection.py</code> of the release package.</p>
<h1><a class="anchor" id="sct_rdk_python_recording"></a>
3 Using a saved Recording</h1>
<p>This section illustrates the usage of the SDK python wrapper with a saved recording. Typically, a program connects to the Radar sensor, but you can also utilize a saved recording to emulate the device usage.</p>
<h2><a class="anchor" id="sct_rdk_python_recording_opening"></a>
3.1 Opening a device from Recording</h2>
<p>To open a dummy device handle from the saved recording, you can use a special version of Device constructor. For this you will need to open a recording first using class Recording. Assuming the recording 'RadarIfxAvian_00' is in your script's directory in a parent directory named 'recording_parent_path' and all dependencies are also available:</p>
<dl class="section user"><dt>Code Listing 3.1.1</dt><dd><pre class="fragment">recording = Recording(path = 'recording_parent_path', mode = 0, type = 0, index = 0);
</pre></dd></dl>
<p>The parameters in the constructor:</p>
<p>The first parameter is a string path to the parent directory containing a recording catalog. The second parameter is a mode represented by a number, where 0 is read mode. Currently only read mode is available. The third parameter is a device type represented by a number, where 0 is Avian device. Currently only Avian radar devices (0) are supported. The fourth parameter is an index number of the recording catalog.</p>
<p>Then you can create a Device with the Recording instance 'recording':</p>
<dl class="section user"><dt>Code Listing 3.1.2</dt><dd><pre class="fragment">device = Device(recording = recording, correct_timing = True);
</pre></dd></dl>
<p>The second parameter in the constructor - 'correct_timing' specifies, if the device simulation should also simulate the timing of the recorded data. This means, when correct_timing is True - you will receive the data only after a minimum of 'frame_repetition_time_s' has passed since last read or acquisition start. Otherwise, the frame will be returned immediately.</p>
<p>You will need to then close both the Device and the Recording:</p>
<dl class="section user"><dt>Code Listing 3.1.3</dt><dd><pre class="fragment">del device
del recording
</pre></dd></dl>
<p>Or you can use a Python 'with' syntax, like in example_recording.py:</p>
<dl class="section user"><dt>Code Listing 3.1.4</dt><dd><pre class="fragment">with Recording(path = path_to_recording_parent_dir, mode = 0, type = 0, index = 0) as recording:
    with Device(recording = recording, correct_timing = True) as device:
        # perform actions on device created from recording
</pre></dd></dl>
<h2><a class="anchor" id="sct_rdk_python_recording_usage"></a>
3.2 Using a device created from Recording</h2>
<p>You can then use all the methods of Device class, but practically the recording offers to read the configuration (not save) and read the data (recorded frames).</p>
<p>To read the configuration one can use a script:</p>
<dl class="section user"><dt>Code Listing 3.2.1</dt><dd><pre class="fragment">current_config = device.get_config();
</pre></dd></dl>
<p>To read the recorded data one can use a script like for a regular device:</p>
<dl class="section user"><dt>Code Listing 3.2.2</dt><dd><pre class="fragment"># A loop for fetching a finite number of frames
for frame_number in range(5):
   frame = device.get_next_frame()
   # processing function for the data can be added here
end
</pre></dd></dl>
<p>If you will get out of recorded frames while reading - a proper error (IFX_ERROR_END_OF_FILE) will be raised, as there is no more frames to be read. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu Nov 17 2022 17:04:51 for Radar SDK Documentation by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
